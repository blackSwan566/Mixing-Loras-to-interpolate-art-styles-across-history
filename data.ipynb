{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_with_labels.tar erfolgreich erstellt in /Users/fionalau/Downloads/toy_tar\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "\n",
    "def create_tar_with_labels(image_folder, label_folder, output_folder, tar_name=\"dataset_with_labels.tar\"):\n",
    "    # make sure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # path to new tar\n",
    "    output_path = os.path.join(output_folder, tar_name)\n",
    "\n",
    "    # Tar archiv\n",
    "    with tarfile.open(output_path, \"w\") as tar:\n",
    "        for image_path in Path(image_folder).glob(\"*.jpg\"):  # todo: make sure its jpg\n",
    "            # Add imgs to tar\n",
    "            tar.add(image_path, arcname=image_path.name)\n",
    "            \n",
    "            #Search Labels\n",
    "            label_path = Path(label_folder) / image_path.with_suffix(\".json\").name\n",
    "            if label_path.exists():\n",
    "              \n",
    "                tar.add(label_path, arcname=label_path.name)\n",
    "            else:\n",
    "                print(f\"Warnung: Keine passende Label-Datei fÃ¼r {image_path.name} gefunden\")\n",
    "\n",
    "    print(f\"{tar_name} erfolgreich erstellt in {output_folder}\")\n",
    "\n",
    "#Todo: where do we add the data?\n",
    "image_folder = \"path to dataset\"       \n",
    "label_folder = \"path to label\"      \n",
    "output_folder = \"path to output folder\"    \n",
    "\n",
    "\n",
    "create_tar_with_labels(image_folder, label_folder, output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/fionalau/miniconda3/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/fionalau/miniconda3/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/fionalau/miniconda3/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/fionalau/miniconda3/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/fionalau/miniconda3/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/fionalau/miniconda3/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/fionalau/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/fionalau/miniconda3/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import webdataset as wds\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Normalization and pre processing\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "preproc = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# path to tar\n",
    "tar_path = \"path to tar\"\n",
    "\n",
    "# Set up webdataset\n",
    "dataset = (\n",
    "    wds.WebDataset(tar_path, empty_check=False)\n",
    "    .shuffle(1000)\n",
    "    .decode(\"pil\")\n",
    "    .rename(image=\"jpg\", label=\"json\")\n",
    "    .map_dict(image=preproc)\n",
    "    .to_tuple(\"image\", \"label\")\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=64, num_workers=1)\n",
    "\n",
    "# Check if its possible to load a batch\n",
    "try:\n",
    "    for batch in loader:\n",
    "        images, labels = batch\n",
    "        print(\"batch successfully loaded!\")\n",
    "        print(\" batch shape:\", images.shape)\n",
    "        print(\"Label batch:\", labels)\n",
    "        break  # Load only the first\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error loading data:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
